model:
  in_channels: 1
  num_hidden: 64
  num_res_hidden: 32
  num_res_layers: 2
  embedding_dim: 64
  num_embeddings: 10
  commitment_cost: 0.25
  saved_models_dir: tmp.monitor_mnist/trained_models_mnist/
  checkpoint: None
  rng: 313
  decay: 0.99

train:
  batch_size: 32
  num_training_updates: 25000 
  learning_rate: 1.5e-4
  weight_decay: 1.0e-5
  decay: 0.99 # For VQ with EMA (to be implemented later)
  num_epochs: 30
  save_param_step_interval: 5
  logger_step_interval: 1000
  learning_rate_decay_epochs: []
  learning_rate_decay_factor: 1
  solver: adam

val:
  batch_size: 32
  interval: 1

monitor:
  path: tmp.monitor_mnist/
  train_loss: Training-loss-mnist 
  train_recon: Training-reconstructions-mnist
  val_loss: Validation-loss-mnist 
  val_recon: Validation-reconstructions-mnist

dataset:
  name: mnist
  train_size: 50000
  val_size: 10000
  with_memory_cache: False
  with_file_cache: False
  shuffle: True


extension_module: cudnn
device_id: '0'
